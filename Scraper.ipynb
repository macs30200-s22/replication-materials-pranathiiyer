{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "090199ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests \n",
    "import bs4 \n",
    "import pandas \n",
    "\n",
    "import re \n",
    "import urllib.parse \n",
    "import io \n",
    "import json \n",
    "import os.path \n",
    "import os \n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93163df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextFromTribunePage(targetURL, file_1, file_2):\n",
    "    r = requests.get(targetURL)\n",
    "    soup = bs4.BeautifulSoup(r.text, 'html.parser')\n",
    "    lst_1 = []\n",
    "    lst_2 = []\n",
    "    contentPTags = soup.findAll('p')\n",
    "    \n",
    "   \n",
    "    if 'class-f' in targetURL:\n",
    "         for ptag in contentPTags:\n",
    "          \n",
    "            new_s = re.sub(r'[\\n,\".—-]','',ptag.text) \n",
    "            new_s1 = (re.sub(r'\\r  {2,}|\\bBox|\\bTribune|\\b([A-Z]*\\d[A-Z]*){5,}\\b|\\bChandigarh|\\bPh|\\b-OL|\\s+$'\\\n",
    "                                        ,' ',new_s))\n",
    "                \n",
    "            lst_2.append(re.sub(r'\\(\\d+\\)|\\s*$', '', new_s1))\n",
    "            with open(file_1, 'a') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([re.sub(r'\\(\\d+\\)|\\s*$', '', new_s1)] )\n",
    "    if 'class-m' in targetURL:\n",
    "        for ptag in contentPTags:\n",
    "            new_s = re.sub(r'[\\n,\".—-]','',ptag.text) \n",
    "            new_s1 = (re.sub(r'\\r  {2,}|\\bBox|\\bTribune|\\b([A-Z]*\\d[A-Z]*){5,}\\b|\\bChandigarh|\\bPh|\\b-OL|\\s+$'\\\n",
    "                                        ,' ',new_s))\n",
    "                \n",
    "          \n",
    "            lst_1.append(re.sub(r'\\(\\d+\\)|\\s*$', '', new_s1))\n",
    "            with open(file_2, 'a') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([re.sub(r'\\(\\d+\\)|\\s*$', '', new_s1)] )\n",
    "        \n",
    "                \n",
    "    return pandas.DataFrame({'Grooms-wanted' : pandas.Series(lst_1), 'Brides-wanted':pandas.Series(lst_2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "acee1bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_urls(year, base_url):\n",
    "\n",
    "\n",
    "    url_request = requests.get(base_url)\n",
    "    web_page_soup = bs4.BeautifulSoup(url_request.text,'html.parser')\n",
    "\n",
    "    tagLinks = web_page_soup.findAll('a', attrs={'href': re.compile(year)})\n",
    "\n",
    "    final_urls = set()\n",
    "\n",
    "    for aTag in tagLinks:\n",
    "            relurl = aTag.get('href')\n",
    "\n",
    "            level_1_request = requests.get(relurl)\n",
    "            level_1_soup = bs4.BeautifulSoup(level_1_request.text, 'html.parser')\n",
    "            level_1_tagLinks = level_1_soup.findAll('a',href = re.compile('class'), class_=False)\n",
    "           \n",
    "\n",
    "            for a1Tag in level_1_tagLinks:\n",
    "                relurl = a1Tag.get('href')\n",
    "            \n",
    "                level_2_url = 'https://www.tribuneindia.com/'+year+re.sub(r'^..','',relurl)\n",
    "               \n",
    "                final_urls.add(level_2_url)\n",
    "    return final_urls\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2765016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def url_csv(year, base_url):\n",
    "    final_df = pandas.DataFrame()\n",
    "    final_urls = get_final_urls(year, base_url)\n",
    "    for url in final_urls:\n",
    "        \n",
    "        try:\n",
    "            print(url)\n",
    "            final_df = final_df.append(getTextFromTribunePage(url,'grooms-wanted_'+year+'.csv','brides-wanted_'+year+'.csv'),ignore_index = True)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a50b3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-137ccf9676c1>:33: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  return pandas.DataFrame({'Grooms-wanted' : pandas.Series(lst_1), 'Brides-wanted':pandas.Series(lst_2)})\n"
     ]
    }
   ],
   "source": [
    "url_csv('2010', 'https://www.tribuneindia.com/2014/forms/arc10.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdc3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3f70e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
